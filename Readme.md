# AI vs Real Image Detection Project

## Overview

This project explores various machine learning and deep learning techniques to distinguish between images generated by Artificial Intelligence (AI) and real photographs. As AI image generation models become increasingly sophisticated, the ability to automatically detect AI-generated content is crucial for combating misinformation, ensuring authenticity, and maintaining digital trust.

This repository contains the implementation and evaluation of several detection methods, ranging from classical machine learning baselines to state-of-the-art deep learning approaches.

## Methods Implemented

The following methods for AI-generated image detection have been implemented and evaluated:

1.  **Classical ML Baseline (SVM):**
    * Utilizes traditional machine learning with handcrafted features (e.g., color histograms, texture descriptors, noise levels).
    * A Support Vector Machine (SVM) is trained on these features for classification.

2.  **DIRE (Diffusion Reconstruction Error):**
    * Leverages the concept that diffusion models can reconstruct images generated by similar processes with low error, while real images or images from different sources will have higher reconstruction errors.
    * A ResNet-50 model is trained on DIRE features.
    * *Reference: "DIRE for Diffusion-Generated Image Detection" (Wang et al., 2023)*

3.  **Few-Shot Detector (FSD - Paper Implementation):**
    * Based on prototypical networks and episodic training to learn a metric space where images from the same class cluster together.
    * Aims to classify images using few examples.
    * *Reference: "Few-Shot Learner Generalizes Across AI-Generated Image Detection" (Wu et al., 2024)*

4.  **Custom Few-Shot Inspired Detector:**
    * Our modified approach using a ResNet-50 backbone.
    * Employs a hybrid loss function combining standard Binary Cross-Entropy (BCE) loss for direct classification with a prototypical loss component to encourage a well-structured feature space.
    * The prototypical loss helps in creating distinct clusters for AI and Real image features by minimizing intra-class variance and maximizing inter-class variance with respect to class prototypes calculated per batch.

5.  **SSP (Single Simple Patch):**
    * Hypothesizes that a single, simple patch (e.g., an area of uniform color) within an image can reveal whether it's real or AI-generated.
    * Real images rarely contain perfectly uniform patches, while AI generators might produce unnaturally smooth areas.
    * *Reference: "A Single Simple Patch is All You Need for AI-generated Image Detection" (Chen et al., 2024)*

## Performance Summary

The following table summarizes the validation accuracies achieved by each method on the test set from the `alessandrasala79/ai-vs-human-generated-dataset` on Kaggle:

| Method                              | Validation Accuracy |
| :---------------------------------- | :------------------ |
| Classical ML Baseline (SVM)         | 94.75%              |
| DIRE                                | 92.4%               |
| Few-Shot Detector (Paper Impl.)     | 79.0%               |
| **Custom Few-Shot Inspired Detector** | **96.8%** |
| SSP (Single Simple Patch)           | 87.07%              |

## Directory Structure

```
.
├── DIRE/                             # Implementation of DIRE method
│   ├── guided-diffusion/             # Submodule for DIRE computation
│   ├── networks/
│   ├── utils/
│   └── train.py, test.py, demo.py
├── SSP-AI-Generated-Image-Detection/ # Implementation of SSP method
│   ├── checkpoint/
│   ├── figures/
│   ├── networks/
│   ├── utils/
│   └── train_val.py, test.py
├── baseline.py                       # Script for Classical ML Baseline (SVM)
├── baseline_model.pkl                # Saved SVM model
├── download.ipynb                    # Jupyter notebook for dataset download/preparation
├── fsd.py                            # Script for Paper Few-Shot Inspired Detector (Our implementation)
├── fsd.pth                           # Saved model for Custom FSD
└── train_fsd.py                      # Script for Our Few-Shot Inspired Detector (Modified Loss)
```

* **DIRE/**: Contains all code, models, and instructions related to the DIRE method. 
* **SSP-AI-Generated-Image-Detection/**: Contains all code, models, and instructions related to the SSP method. 
* **Root Directory Files**:
    * `baseline.py`: Trains and evaluates the SVM baseline.
    * `fsd.py`: Implements the Custom Few-Shot Inspired Detector (our best-performing model). The paper's FSD version (79% accuracy) was an earlier iteration based on the code provided in the prompt.
    * `download.ipynb`: Utility for downloading the dataset.

## Setup and Installation

1.  **Clone the repository (if applicable).**
2.  **Python Environment:** It is recommended to use a virtual environment (e.g., conda or venv) with Python 3.9+.
3.  **General Dependencies:** While specific models have their own `requirements.txt`, common libraries include:
    * PyTorch
    * Torchvision
    * NumPy
    * Pandas
    * Scikit-learn
    * Pillow (PIL)
    * Matplotlib
    * tqdm

4.  **Model-Specific Dependencies:**
    * For **DIRE**, navigate to the `DIRE/` directory and install its requirements:
        ```bash
        cd DIRE
        pip install -r requirements.txt
        cd ..
        ```
    * For **SSP**, navigate to the `SSP-AI-Generated-Image-Detection/` directory and install its requirements:
        ```bash
        cd SSP-AI-Generated-Image-Detection
        pip install -r requirements.txt
        cd ..
        ```
    * For the **Custom FSD** and **Baseline SVM** (in the root directory), ensure PyTorch, scikit-learn, pandas, and other common libraries are installed:
        ```bash
        pip install -r requirements.txt
        ```


## Dataset

The primary dataset used for this project is the **"AI vs Human Generated Dataset"** available on Kaggle:
[https://www.kaggle.com/datasets/alessandrasala79/ai-vs-human-generated-dataset](https://www.kaggle.com/datasets/alessandrasala79/ai-vs-human-generated-dataset)

Refer to the `download.ipynb` notebook for guidance on downloading and preparing the dataset. Ensure the dataset paths in the configuration files or scripts for each model are updated accordingly. The expected structure is a CSV file mapping image filenames to labels, and a directory containing the actual image files.

## Usage / Running the Models

Modify dataset paths and hyperparameters within the respective scripts or configuration files as needed.

### 1. Classical ML Baseline (SVM)

* **Script:** `baseline.py`
* **To run:**
    ```bash
    python baseline.py --csv_path /path/to/your/train_val.csv --data_root /path/to/your/images/ --model_save_path ./baseline_model.pkl
    ```
    The script will extract features, train the SVM, evaluate it, and save the model.

### 2. DIRE (Diffusion Reconstruction Error)

* Refer to the `DIRE/README.md` for detailed instructions.
* **DIRE Score Computation:** Uses scripts in `DIRE/guided-diffusion/`, typically `compute_dire.sh` and `compute_dire.py`.
* **Training Classifier:**
    ```bash
    cd DIRE
    # Modify train.sh with correct paths and parameters
    bash train.sh
    ```
* **Testing Classifier:**
    ```bash
    cd DIRE
    # Modify test.sh with correct paths and parameters
    bash test.sh
    ```

### 3. Few-Shot Detectors

#### a. Paper Implementation (Prototypical Network)
* The code for this version (achieving 79% accuracy) was based on the initial FSD paper's approach using episodic training. If you have a dedicated script for this, adapt the following. The old `fsd.py` (as provided in the prompt context) would be used.
* **Example (conceptual, adapt based on your actual script for this version):**
    ```bash
    python path/to/old_fsd_paper_impl.py --csv_path /path/to/train.csv --data_root /path/to/images/ --epochs 10 --save_path ./fsd_paper.pth
    ```

#### b. Custom Few-Shot Inspired Detector (Our Best Model - 97.62%)
* **Script:** `fsd.py` (in the root directory)
* **To Train & Evaluate:**
    ```bash
    python fsd.py --csv_path /path/to/your/train.csv \
                  --data_root /path/to/your/images/ \
                  --save_path ./fsd_custom.pth \
                  --epochs 10 \
                  --batch_size 32 \
                  --lr 1e-4 \
                  --proto_weight 0.5 \
                  --train_size 8000 \
                  --test_size 800
    ```

### 4. SSP (Single Simple Patch)

* Refer to `SSP-AI-Generated-Image-Detection/README.md` for detailed instructions.
* **Training and Validation:**
    ```bash
    cd SSP-AI-Generated-Image-Detection
    # Modify train_val.sh with correct dataset paths, model name, etc.
    bash train_val.sh
    ```
* **Testing:**
    ```bash
    cd SSP-AI-Generated-Image-Detection
    bash test.sh
    ```
    A pre-trained model is available at `SSP-AI-Generated-Image-Detection/checkpoint/Net_epoch_best.pth`.

## Results

The performance of each model is summarized in the [Performance Summary](#performance-summary) section. Our Custom Few-Shot Inspired Detector achieved the highest validation accuracy of 97.62%. 

## References

* **DIRE:** Wang, Z., Bao, J., Zhou, W., Wang, W., Hu, H., Chen, H., & Li, H. (2023). DIRE for Diffusion-Generated Image Detection. *arXiv preprint arXiv:2303.09295*.
* **SSP:** Chen, J., Yao, J., & Niu, L. (2024). A Single Simple Patch is All You Need for AI-generated Image Detection. *arXiv preprint arXiv:2404.13416*.
* **FSD:** Wu, S., Liu, J., Li, J., & Wang, Y. (2024). Few-Shot Learner Generalizes Across AI-Generated Image Detection. *arXiv preprint arXiv:2401.07701*.

## Team

* Yatharth Gupta
* Bijeesh K

Pattern Recognition Project, Prof. Somnath Dey, Indian Institute of Technology, Indore.
